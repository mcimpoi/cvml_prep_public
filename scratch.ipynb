{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformer.model import EncoderLayer\n",
    "from transformer.visualization import show_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# From notebook\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "\n",
    "    def __init__(self, size, padding_idx, smoothing=0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        plt.figure(figsize=(10, 20))\n",
    "        assert x.size(1) == self.size\n",
    "        # print(f\"X: {x.shape} Target: {target.shape}\")\n",
    "        \n",
    "        plt.title(\"True dist X(clone)\")\n",
    "        true_dist = torch.ones_like(x) * (self.smoothing / (self.size - 2))\n",
    "        plt.subplot(1, 6, 2)\n",
    "        plt.imshow(true_dist)\n",
    "        plt.title(\"True dist (fill)\")\n",
    "        \n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        plt.subplot(1, 6, 3)\n",
    "        plt.imshow(true_dist)\n",
    "        plt.title(\"True dist (scatter)\")\n",
    "\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        plt.subplot(1, 6, 4)\n",
    "        plt.imshow(true_dist)\n",
    "        plt.title(\"True dist (padding)\")\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        plt.subplot(1, 6, 5)\n",
    "        plt.imshow(mask)\n",
    "        # plt.colorbar()\n",
    "        plt.title(\"Mask\")\n",
    "        print(f\"Mask: {mask}\")\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "            plt.subplot(1, 6, 6)\n",
    "            plt.imshow(true_dist)\n",
    "            plt.title(\"True dist (index fill)\")\n",
    "            plt.colorbar()\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, self.true_dist.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothing(5, padding_idx=0, smoothing=0.4)\n",
    "\n",
    "predict = torch.FloatTensor(\n",
    "    [\n",
    "        [0, 0.2, 0.7, 0.1, 0],\n",
    "        [0, 0.2, 0.7, 0.1, 0],\n",
    "        [0, 0.2, 0.7, 0.1, 0],\n",
    "        [0, 0.2, 0.7, 0.1, 0],\n",
    "        [0, 0.2, 0.7, 0.1, 0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "v = criterion(predict, torch.LongTensor([2, 1, 0, 3, 3]))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion.true_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.LongTensor([2,1,0,3,3])\n",
    "padding_idx = 0\n",
    "mask = torch.nonzero(target.data == padding_idx)\n",
    "mask.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loss(x, crit):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0.001, x / d, 1 / d, 1 / d, 1 / d]])\n",
    "    return crit(predict.log(), torch.LongTensor([1])).data\n",
    "\n",
    "crit = LabelSmoothing(5, 0, 0.1)\n",
    "loss_data = pd.DataFrame(\n",
    "        {\n",
    "            \"Loss\": [loss(x, crit) for x in range(1, 100)],\n",
    "            \"Steps\": list(range(99)),\n",
    "        }\n",
    "    ).astype(\"float\")\n",
    "\n",
    "loss_data.plot(x=\"Steps\", y=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_ = nn.KLDivLoss(reduction=\"sum\")\n",
    "crit_(predict.log(), predict.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.normal(0, 1, (2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = torch.normal(0, 1, (2, 1, 2))\n",
    "keys = torch.normal(0, 1, (2, 10, 2))\n",
    "values = torch.normal(0, 1, (2, 10, 4))\n",
    "\n",
    "attn = DotProductAttention(dropout_prob=0.0)\n",
    "attn(queries, keys, values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries @ keys.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bmm(queries, keys.transpose(1,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys.transpose(-2, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention(queries, keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmaps(attn.attention_weights.reshape((1,1,2,10)), xlabel=\"Keys\", ylabel=\"Queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "\n",
    "d_model = 64\n",
    "d_k = 16\n",
    "n_heads = 4\n",
    "\n",
    "WQ = nn.Linear(d_model, d_model)\n",
    "WK = nn.Linear(d_model, d_model)\n",
    "WV = nn.Linear(d_model, d_model)\n",
    "\n",
    "\n",
    "emb = nn.Embedding(100, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " = torch.randint(0, vocab_size, (1, 10))\n",
    "print(x.shape, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WQ.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = WQ(emb(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q.shape)\n",
    "n_batches = 1\n",
    "n_heads = 4\n",
    "d_k = 16\n",
    "\n",
    "WQ(x).view(n_batches, -1, n_heads, d_k).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module,\n",
    "                 encoder_embedding, src_vocab_size: int, tgt_vocab_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.src_embedding = nn.Embedding(d_model, src_vocab_size)\n",
    "        self.tgt_embedding = nn.Embedding(d_model, tgt_vocab_size)\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        return self.encode(src, src_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.src_embedding(src)\n",
    "        return self.encoder(x, src_mask)\n",
    "    \n",
    "def make_model(src_vocab_size, tgt_vocab_size, n_blocks=2):\n",
    "    model = EncoderDecoder(Encoder(EncoderLayer(), n_blocks), decoder=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]])\n",
    "src_mask = torch.ones((1,1,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "from transformer.model import EncoderLayer\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_blocks: int, d_model: int, num_heads: int) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads) for _ in range(n_blocks)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, src_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64 \n",
    "Wq = nn.Linear(d_model, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 11\n",
    "d_model = 64\n",
    "emb = nn.Embedding(src_vocab_size, d_model)\n",
    "src = torch.LongTensor([[1,2,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,8,10]])\n",
    "x = emb(src)\n",
    "enc = Encoder(n_blocks=2, d_model=d_model, num_heads=4)\n",
    "enc(x, src_mask=None).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(1000,128)\n",
    "embedding(torch.LongTensor([3,4])).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\" Implements FFN eqn 2 \"\"\"\n",
    "    def __init__(self, d_model: int, d_ff:int, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(torch.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EncoderLayer(d_model, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wq = nn.Linear(d_model, d_model)\n",
    "Wk = nn.Linear(d_model, d_model)\n",
    "Wv = nn.Linear(d_model, d_model)\n",
    "Wo = nn.Linear(d_model, d_model)\n",
    "\n",
    "query = emb(src)\n",
    "\n",
    "Q = Wq(query)\n",
    "\n",
    "key = emb(src)\n",
    "K = Wk(key)\n",
    "\n",
    "value = emb(src)\n",
    "V = Wv(value)\n",
    "\n",
    "x_out, _ = attention(Q, K, V)\n",
    "\n",
    "\n",
    "print(\"after attn: \", x_out.shape)\n",
    "n_batches = query.shape[0]\n",
    "x_out = x_out.transpose(1, 2).contiguous().view(n_batches, -1, d_model)\n",
    "print(x_out.shape)\n",
    "X_out = Wo(x_out)\n",
    "\n",
    "print(X_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out, _ = attention(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out.transpose(1, 2).contiguous().view(n_batches, -1, d_model).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query.shape)\n",
    "n_heads = 4\n",
    "\n",
    "Q = Wq(query).view(n_batches, -1, n_heads, d_model // n_heads).transpose(1,2)\n",
    "print(Wq(query).shape)\n",
    "\n",
    "K = Wk(key).view(n_batches, -1, 4, 16).transpose(1,2)\n",
    "V = Wv(value).view(n_batches, -1, 4, 16).transpose(1,2)\n",
    "\n",
    "\n",
    "def attention( query, key, value, mask=None, dropout_prob=None):\n",
    "        # query: (batch_size, n_queries, d_model)\n",
    "        # key: (batch_size, n_keys, d_model)\n",
    "        # value: (batch_size, n_keys, d_model)\n",
    "        # ?? mask: (batch_size, n_queries, n_keys)\n",
    "    d_k = query.size(-1)\n",
    "    print(d_k)        \n",
    "        #logger.info(f\"query shape: {query.shape} d_k: {d_k}\")\n",
    "\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / d_k**0.5\n",
    "    print(f\"scores: {scores.shape}, key: {key.shape}, query: {query.shape}\")\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    print(f\"Attention shape: {p_attn.shape}\" )\n",
    "    if dropout_prob is not None:\n",
    "        p_attn = nn.Dropout(dropout_prob)(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, probs = attention(Q, K, V)\n",
    "print(x.shape)\n",
    "\n",
    "y_ = x.transpose(1, 2).contiguous().view(n_batches, -1, d_model)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
