{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following from: https://www.youtube.com/watch?v=PaCmpygFfXo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas to follow up:\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {} # bigram count\n",
    "for w in words:\n",
    "    chs = [\"<S>\"] + list(w) + [\"<E>\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        b[bigram] = b.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(b.items(), key=lambda kv:kv[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros(27, 27)\n",
    "\n",
    "for w in words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        idx1 = s2i[ch1]\n",
    "        idx2 = s2i[ch2]\n",
    "        N[idx1, idx2] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(N, cmap=\"Blues\")\n",
    "\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = i2s[i] + i2s[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
    "        plt.text(j, i, f\"{N[i, j].item()}\", ha=\"center\", va=\"top\", color=\"gray\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = N[0].float()\n",
    "prob /= prob.sum()\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "p = torch.rand(3, generator=g)\n",
    "p = p/p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multinomial(p, num_samples=20, replacement=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "idx = torch.multinomial(prob, num_samples=1, replacement=True, generator=g).item()\n",
    "i2s[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read about broadcasting\n",
    "P = (N + 1).float()\n",
    "P /= P.sum(dim=1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    out = []\n",
    "    idx = 0\n",
    "    while True:\n",
    "        # p = torch.ones(27) / 27.0\n",
    "        idx = torch.multinomial(P[idx], num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(i2s[idx])\n",
    "        if idx == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: trigram; n-gram;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelyhood = 0.0\n",
    "n = 0\n",
    "for w in [\"mircea\"]:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        idx1, idx2 = s2i[ch1], s2i[ch2] \n",
    "        logprob = torch.log(P[idx1, idx2]).item()\n",
    "        log_likelyhood += logprob\n",
    "        n += 1\n",
    "        print(f\"{ch1}{ch2} : {P[idx1, idx2].item():.3f} {logprob:.3f}\")\n",
    "\n",
    "nll = - log_likelyhood\n",
    "print(f\"negative_log_likelyhood: {nll:.3f}\")\n",
    "print(f\"{nll / n:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maximum likelihood estimation (wiki)\n",
    "# log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set of bigrams\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\t\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        idx1, idx2 = s2i[ch1], s2i[ch2]\n",
    "        # print(ch1, ch2)\n",
    "        xs.append(idx1)\n",
    "        ys.append(idx2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "num = xs.nelement()\n",
    "print(f\"number of examples: {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.functional.one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = F.one_hot(xs, num_classes=27).float()\n",
    "x_enc.shape\n",
    "plt.imshow(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27, 27))\n",
    "# (5, 27) @ (27, 27) = (5, 27)\n",
    "(x_enc @ W)[3,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = x_enc @ W # log-counts\n",
    "counts = logits.exp()\n",
    "\n",
    "prob = counts / counts.sum(dim=1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g)\n",
    "x_enc = F.one_hot(xs, num_classes=27).float()\n",
    "logits = x_enc @ W # log-counts\n",
    "# softmax\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    print(\"-----------------------------------\")\n",
    "    print(f\"Example: {i2s[x]} -> {i2s[y]}, indices {x} -> {y}\")\n",
    "    p = probs[i, y]\n",
    "    logp = torch.log(p)\n",
    "    print(f\"Log likelyhood: {logp:.3f}\")\n",
    "    nlls[i] = -logp\n",
    "print(f\"Average log likelyhood: {nlls.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -probs[torch.arange(5), ys].log().mean() # nll; idx1: 0..5; idx2: ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = torch.Generator().manual_seed(2147483647)\n",
    "# W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "\n",
    "# forward pass\n",
    "x_enc = F.one_hot(xs, num_classes=27).float()\n",
    "logits = x_enc @ W # log-counts\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "loss = -probs[torch.arange(5), ys].log().mean() # nll; idx1: 0..5; idx2: ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # mored efficient than W.zero_grad() ???\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "\n",
    "n_iter = 100\n",
    "num_elements = xs.nelement()\n",
    "learning_rate = 50\n",
    "\n",
    "for k in range(n_iter):\n",
    "    # forward pass\n",
    "    x_enc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = x_enc @ W # log-counts\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num_elements), ys].log().mean() + 0.001 * (W ** 2).mean() # nll; idx1: 0..5; idx2: ys\n",
    "    if k % 10 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None \n",
    "    loss.backward()\n",
    "\n",
    "    # update W:\n",
    "    W.data += -learning_rate * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(W **2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        x_enc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = x_enc @ W \n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(i2s[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
